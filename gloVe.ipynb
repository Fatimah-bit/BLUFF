{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchtext import data\nfrom torchtext import datasets","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn, optim","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HEADLINE = data.Field(tokenize='spacy', include_lengths = True)\nISSARCASTIC = data.LabelField()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fields = {\n    'headline':('headline', HEADLINE),\n    'is_sarcastic':('sarcastic', ISSARCASTIC)\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sarcasm_data = data.TabularDataset(\n    path='/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset_v2.json',\n    format='json',\n    fields=fields\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(vars(sarcasm_data[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data, test_data = sarcasm_data.split()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_VOCAB_SIZE = 50_000","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HEADLINE.build_vocab(train_data, \n                 max_size = MAX_VOCAB_SIZE, \n                 vectors = \"glove.6B.100d\", \n                 unk_init = torch.Tensor.normal_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ISSARCASTIC.build_vocab(train_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 64\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ntrain_iterator, test_iterator = data.BucketIterator.splits(\n    (train_data, test_data), \n    batch_size = BATCH_SIZE,\n    sort_key = lambda x:len(x.headline),\n    sort_within_batch = True,\n    device = device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RNN(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n                 bidirectional, dropout, pad_idx):\n        super(RNN, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional,\n                          dropout=dropout)\n        self.fc = nn.Linear(hidden_dim*2, output_dim)\n        self.dropout = nn.Dropout(dropout)\n    def forward(self, text, text_lengths):\n        embedded = self.dropout(self.embedding(text))\n        \n        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n        return self.fc(hidden)\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_DIM = len(HEADLINE.vocab)\nEMBEDDING_DIM = 100\nHIDDEN_DIM = 256\nOUTPUT_DIM = 1\nN_LAYERS = 2\nBIDIRECTIONAL = True\nDROPOUT = 0.5\nPAD_IDX = HEADLINE.vocab.stoi[HEADLINE.pad_token]\n\nmodel = RNN(INPUT_DIM, \n            EMBEDDING_DIM, \n            HIDDEN_DIM, \n            OUTPUT_DIM, \n            N_LAYERS, \n            BIDIRECTIONAL, \n            DROPOUT, \n            PAD_IDX)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f'The model has {count_parameters(model):,} trainable parameters')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained_embeddings = HEADLINE.vocab.vectors\n\nprint(pretrained_embeddings.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.embedding.weight.data.copy_(pretrained_embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"UNK_IDX = HEADLINE.vocab.stoi[HEADLINE.unk_token]\n\nmodel.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\nmodel.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n\nprint(model.embedding.weight.data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\n\noptimizer = optim.Adam(model.parameters())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\n\nmodel = model.to(device)\ncriterion = criterion.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def binary_accuracy(preds, y):\n    \"\"\"\n    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n    \"\"\"\n\n    #round predictions to the closest integer\n    rounded_preds = torch.round(torch.sigmoid(preds))\n    correct = (rounded_preds == y).float() #convert into float for division \n    return correct.sum() / len(correct)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, iterator, optimizer, criterion):\n    epoch_loss = 0.0\n    epoch_acc = 0.0\n    for batch in iterator:\n        optimizer.zero_grad()\n        text, text_lengths = batch.headline\n        \n        predictions = model(text, text_lengths).squeeze(1)\n#         print(predictions)\n        loss = criterion(predictions, batch.sarcastic.type_as(predictions))\n        acc = binary_accuracy(predictions, batch.sarcastic.type_as(predictions))\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n        epoch_acc += acc.item()\n    return epoch_loss / len(iterator), epoch_acc / len(iterator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\n\ndef epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_EPOCHS = 5\n\n\nfor epoch in range(N_EPOCHS):\n\n    start_time = time.time()\n    \n    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n    \n    end_time = time.time()\n\n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n    \n    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, iterator, criterion):\n    \n    epoch_loss = 0\n    epoch_acc = 0\n    \n    model.eval()\n    \n    with torch.no_grad():\n    \n        for batch in iterator:\n\n            text, text_lengths = batch.headline\n            \n            predictions = model(text, text_lengths).squeeze(1)\n            \n            loss = criterion(predictions, batch.sarcastic.type_as(predictions))\n            \n            acc = binary_accuracy(predictions, batch.sarcastic.type_as(predictions))\n\n            epoch_loss += loss.item()\n            epoch_acc += acc.item()\n        \n    return epoch_loss / len(iterator), epoch_acc / len(iterator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.load_state_dict(torch.load('tut2-model.pt'))\n\ntest_loss, test_acc = evaluate(model, test_iterator, criterion)\n\nprint(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import spacy\nnlp = spacy.load('en')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_sarcasm(model, sentence):\n    model.eval()\n    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n    indexed = [HEADLINE.vocab.stoi[t] for t in tokenized]\n    length = [len(indexed)]\n    tensor = torch.LongTensor(indexed).to(device)\n    tensor = tensor.unsqueeze(1)\n    length_tensor = torch.LongTensor(length)\n    prediction = torch.sigmoid(model(tensor, length_tensor))\n    return prediction.item()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_sarcasm(model, \"She gave him a sarcastic smile.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}